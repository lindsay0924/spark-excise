# -*- coding: utf-8 -*-
"""Monetree-Spark-linqian.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rcaUWIgI1CSx1wM2qLXYf9Y6qdsr1XR-
"""

import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions._
import org.apache.spark.sql.expressions.Window

// Step 1: Create a Spark session
val spark = SparkSession.builder().appName("ShareAggregation").getOrCreate()

// Step 2: Read the input data
val data = Seq(
  ("Jan 1, 2021", 7203, 10, 1),
  ("Jan 1, 2021", 3382, 30, 1),
  ("Jan 4, 2021", 7203, 20, 1),
  ("Jan 10, 2021", 7203, 30, 1),
  ("Jan 10, 2021", 3382, 40, 1)
)

val df = data.toDF("Date", "Ticker", "Quantity", "User ID")

// Step 3: Perform necessary transformations and calculations
val windowSpec = Window.partitionBy("Ticker").orderBy("Date")

val inferredData = df
  .withColumn("PrevDate", lag("Date", 1).over(windowSpec))
  .withColumn("PrevQuantity", lag("Quantity", 1).over(windowSpec))
  .withColumn("Inferred", when($"Date" === date_add($"PrevDate", 1), $"PrevQuantity").otherwise(0))
  .withColumn("Held", $"Quantity" - $"Inferred")
  .withColumn("TotalUsers", lit(1))

// Step 4: Aggregate the data
val result = inferredData
  .groupBy("Date")
  .pivot("Ticker")
  .agg(
    sum("Held").as("Held"),
    sum("Inferred").as("Inferred"),
    countDistinct("User ID").as("Total Users")
  )
  .na.fill(0)

// Step 5: Write the output
result.show()